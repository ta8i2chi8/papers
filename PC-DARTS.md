# PC-DARTS: PARTIAL CHANNEL CONNECTIONS FOR MEMORY-EFFICIENT ARCHITECTURE SEARCH

## １．アブスト
DARTSは、効果的なネットワークアーキテクチャを見つけるための高速なソリューションを提供しますが、スーパーネットワークの学習と最適なアーキテクチャの探索を共同で行うため、メモリと計算のオーバーヘッドが大きくなります。本論文では、スーパーネットワークのごく一部をサンプリングすることで、ネットワーク空間を探索する際の冗長性を減らし、性能を落とすことなく効率的な探索を行う新しいアプローチ、すなわちPartially-Connected DARTSを提案します。具体的には、一部のチャンネルで演算探索を行い、除外された部分はショートカットで迂回するというものです。この戦略では、異なるチャネルをサンプリングすることにより、スーパーネットのエッジを選択する際に望ましくない不整合が発生する可能性があります。この問題を解決するために，エッジの正規化を行い，エッジレベルのパラメータを新たに追加して，探索の不確実性を低減しました．メモリコストの削減により，PC-DARTSはより大きなバッチサイズで学習することができ，その結果，より高速で安定した学習が可能になりました．実験結果は、提案手法の有効性を示すものである。具体的には，CIFAR10において，アーキテクチャ探索にGPUを0.1枚使用しただけで，2.57％のエラーレートを達成し，ImageNet（モバイル環境）において，3.8枚のGPUを使用して24.2％の最先端のトップ1エラーレートを達成した．

## ２．イントロ
* すべてのチャンネルを演算選択のブロックに送る代わりに，各ステップでそのうちのサブセットをランダムにサンプリングし，残りはショートカットで直接バイパスする
* このサブセットでの計算は、すべてのチャンネルでの計算に近似した代理であると仮定
* →メモリと計算コストの大幅な削減に加えて、演算探索が正則化され、局所最適に陥りにくくなるという利点あり
* PC-DARTSでは、反復処理中にチャネルの異なるサブセットがサンプリングされると、チャネルの接続性の選択が不安定になるという副作用があります。そこで、エッジ正規化を導入し、エッジ選択ハイパーパラメータの追加セットを明示的に学習することで、ネットワーク接続性の探索を安定化させます。これらのハイパーパラメータを学習プロセス全体で共有することにより、求められるネットワークアーキテクチャは、イテレーション間でサンプリングされたチャンネルの影響を受けにくくなり、より安定したものとなります。部分接続戦略の利点を活かして、バッチサイズを大幅に増やすことができます。

## ３．proposed method
* partial channel connections(論文図を参照)
*  -> アーキテクチャ探索時の計算コストをK倍に削減することができる
*  -> エッジ(i, j)において、入力xiが与えられた場合、入力チャンネルのごく一部(1／K)だけが演算混合に進み、残りのチャンネルはそのまま残されるので、ハイパーパラメータα(i,j)とα'(i,j)の2つのセットを使用した場合の差は大きく減少します。これにより、Oにおいて重み付きの演算（例えば、様々な種類の畳み込み）よりも重みなしの演算（例えば、スキップ・コネクト、マックス・プーリングなど）が優先されることが正則化される。初期段階では、探索アルゴリズムは重みなしの演算を好むことが多い。これは、訓練するための重みを持たないため、より一貫した出力、すなわち、o(xi)を生成するからである。
* edge normalization
*  -> 反復の間にランダムにサンプリングされたチャネルによって最適化されるため、サンプリングされたチャネルが時間とともに変化すると、それによって決定された最適な接続性が不安定になる可能性があります。これは、結果として得られるネットワークアーキテクチャに望ましくない変動をもたらす可能性があります。この問題を軽減するために、各エッジ(i,j)をβi,jで示すように明示的に重み付けするエッジ正規化を導入した。